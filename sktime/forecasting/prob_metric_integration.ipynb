{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic metric integration\n",
    "After developing probabilistic metrics in #2232 need to ensure they are compatible with useful features such as grid search for model parameters. There are two key problems that need to be solved for this:\n",
    "\n",
    "1. proba metrics take in the output of `predict_quantile` or `predict_interval` (or `predict_proba`) where normal metrics just take predict. This means we need to change what predictions are used inside the grid search.\n",
    "\n",
    "2. Some probabilistic metrics have their own hyperparameters. For example the quantile used in a pinball loss. Currently this is inferred from the data inputted, however for a grid search we will need to somehow tell it what quantile to produce. \n",
    "\n",
    "To solve 1. could either create some `set_default` function which determines what the forecaster implements for predict (_predict, _predict_quantile or _predict_interval) or use tags inside the grid search evaluation that retrieves the type of metric being used and calls the corresponding predict function.\n",
    "\n",
    "To solve 2. we could do a small refactor to the probabilistic metrics, where we specify the hyperprameter(s) we want and it retrieves the correct data from the input (and raises an error if it isn't there). This will allow it to require a specific quantile but reduces flexibility as a user will have to instantiate a new metric class for each different set of quantiles they want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data/forecaster\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "\n",
    "y = np.log1p(load_airline())\n",
    "y_train, y_test = temporal_train_test_split(y)\n",
    "fh = np.arange(len(y_test)) + 1\n",
    "\n",
    "f = ThetaForecaster(sp=12)\n",
    "f.fit(y_train)\n",
    "y_pred = f.predict(fh=fh)\n",
    "q_pred = f.predict_quantiles(fh=fh, alpha=0.5)\n",
    "i_pred = f.predict_interval(fh=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Quantiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1958-01</th>\n",
       "      <td>5.847790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-02</th>\n",
       "      <td>5.841117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-03</th>\n",
       "      <td>5.998219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-04</th>\n",
       "      <td>5.954095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-05</th>\n",
       "      <td>5.950747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Quantiles\n",
       "              0.5\n",
       "1958-01  5.847790\n",
       "1958-02  5.841117\n",
       "1958-03  5.998219\n",
       "1958-04  5.954095\n",
       "1958-05  5.950747"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Coverage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1958-01</th>\n",
       "      <td>5.771386</td>\n",
       "      <td>5.924195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-02</th>\n",
       "      <td>5.750227</td>\n",
       "      <td>5.932007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-03</th>\n",
       "      <td>5.894854</td>\n",
       "      <td>6.101584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-04</th>\n",
       "      <td>5.839605</td>\n",
       "      <td>6.068584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-05</th>\n",
       "      <td>5.826123</td>\n",
       "      <td>6.075371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Coverage          \n",
       "              0.9          \n",
       "            lower     upper\n",
       "1958-01  5.771386  5.924195\n",
       "1958-02  5.750227  5.932007\n",
       "1958-03  5.894854  6.101584\n",
       "1958-04  5.839605  6.068584\n",
       "1958-05  5.826123  6.075371"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define probabilistic metric\n",
    "from sktime.performance_metrics.forecasting.probabilistic import PinballLoss\n",
    "\n",
    "loss = PinballLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0.5\n",
       "0  0.026143"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(y_test, q_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.forecasting.model_selection import (\n",
    "    ExpandingWindowSplitter,\n",
    "    ForecastingGridSearchCV,\n",
    ")\n",
    "\n",
    "cv = ExpandingWindowSplitter(\n",
    "    initial_window=24, step_length=12, fh=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    ")\n",
    "\n",
    "param_grid = {\"sp\": [6, 12]}\n",
    "\n",
    "gcv = ForecastingGridSearchCV(f, cv, param_grid, scoring=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ForecastingGridSearchCV relies on `sktime.forecasting.model_evaluation.evaluate` to evaluate metric scores, hence this is what we will need to change to allow it to work. It also has it's own `score()` function which could also be changed but this isn't used in fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "['y_pred should be a pd.DataFrame', 'y_pred should be a pd.DataFrame']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\e.enticott\\Repositories\\sktime\\sktime\\sktime\\forecasting\\prob_metric_integration.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/e.enticott/Repositories/sktime/sktime/sktime/forecasting/prob_metric_integration.ipynb#ch0000015?line=0'>1</a>\u001b[0m evaluate(f, cv, y_test, scoring \u001b[39m=\u001b[39;49m loss)\n",
      "File \u001b[1;32mc:\\users\\e.enticott\\repositories\\sktime\\sktime\\sktime\\forecasting\\model_evaluation\\_functions.py:122\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(forecaster, cv, y, X, strategy, scoring, fit_params, return_data)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/forecasting/model_evaluation/_functions.py?line=118'>119</a>\u001b[0m pred_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter() \u001b[39m-\u001b[39m start_pred\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/forecasting/model_evaluation/_functions.py?line=120'>121</a>\u001b[0m \u001b[39m# score\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/forecasting/model_evaluation/_functions.py?line=121'>122</a>\u001b[0m score \u001b[39m=\u001b[39m scoring(y_test, y_pred, y_train\u001b[39m=\u001b[39;49my_train)\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/forecasting/model_evaluation/_functions.py?line=123'>124</a>\u001b[0m \u001b[39m# save results\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/forecasting/model_evaluation/_functions.py?line=124'>125</a>\u001b[0m results \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/forecasting/model_evaluation/_functions.py?line=125'>126</a>\u001b[0m     {\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/forecasting/model_evaluation/_functions.py?line=126'>127</a>\u001b[0m         score_name: score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/forecasting/model_evaluation/_functions.py?line=135'>136</a>\u001b[0m     ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/forecasting/model_evaluation/_functions.py?line=136'>137</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\users\\e.enticott\\repositories\\sktime\\sktime\\sktime\\performance_metrics\\forecasting\\probabilistic\\_classes.py:50\u001b[0m, in \u001b[0;36m_BaseProbaForecastingErrorMetric.__call__\u001b[1;34m(self, y_true, y_pred, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, y_true, y_pred, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=32'>33</a>\u001b[0m     \u001b[39m\"\"\"Calculate metric value using underlying metric function.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=33'>34</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=34'>35</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=47'>48</a>\u001b[0m \u001b[39m        Calculated loss metric.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=48'>49</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(y_true, y_pred, multioutput\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultioutput, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\users\\e.enticott\\repositories\\sktime\\sktime\\sktime\\performance_metrics\\forecasting\\probabilistic\\_classes.py:70\u001b[0m, in \u001b[0;36m_BaseProbaForecastingErrorMetric.evaluate\u001b[1;34m(self, y_true, y_pred, multioutput, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=52'>53</a>\u001b[0m \u001b[39m\"\"\"Evaluate the desired metric on given inputs.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=53'>54</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=54'>55</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=66'>67</a>\u001b[0m \u001b[39mloss : pd.DataFrame of shape (, n_outputs), calculated loss metric.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=67'>68</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=68'>69</a>\u001b[0m \u001b[39m# Input checks and conversions\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=69'>70</a>\u001b[0m y_true_inner, y_pred_inner, multioutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_ys(\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=70'>71</a>\u001b[0m     y_true, y_pred, multioutput\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=71'>72</a>\u001b[0m )\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=72'>73</a>\u001b[0m \u001b[39m# pass to inner function\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=73'>74</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluate(y_true_inner, y_pred_inner, multioutput, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\e.enticott\\repositories\\sktime\\sktime\\sktime\\performance_metrics\\forecasting\\probabilistic\\_classes.py:173\u001b[0m, in \u001b[0;36m_BaseProbaForecastingErrorMetric._check_ys\u001b[1;34m(self, y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=167'>168</a>\u001b[0m valid, msg, metadata \u001b[39m=\u001b[39m check_is_scitype(\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=168'>169</a>\u001b[0m     y_pred, scitype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProba\u001b[39m\u001b[39m\"\u001b[39m, return_metadata\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, var_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=169'>170</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=171'>172</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid:\n\u001b[1;32m--> <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=172'>173</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=174'>175</a>\u001b[0m y_pred_mtype \u001b[39m=\u001b[39m metadata[\u001b[39m\"\u001b[39m\u001b[39mmtype\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/users/e.enticott/repositories/sktime/sktime/sktime/performance_metrics/forecasting/probabilistic/_classes.py?line=175'>176</a>\u001b[0m inner_y_pred_mtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_tag(\u001b[39m\"\u001b[39m\u001b[39mscitype:y_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: ['y_pred should be a pd.DataFrame', 'y_pred should be a pd.DataFrame']"
     ]
    }
   ],
   "source": [
    "evaluate(f, cv, y_test, scoring=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we naively substitute the normal loss for a quantile loss we get an input error (as expected).\n",
    "\n",
    "We will first try changing the evaluate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.utils.validation.forecasting import (\n",
    "    check_cv,\n",
    "    check_fh,\n",
    "    check_scoring,\n",
    "    check_X,\n",
    ")\n",
    "from sktime.utils.validation.series import check_series\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    forecaster,\n",
    "    cv,\n",
    "    y,\n",
    "    X=None,\n",
    "    strategy=\"refit\",\n",
    "    scoring=None,\n",
    "    fit_params=None,\n",
    "    return_data=False,\n",
    "):\n",
    "    \"\"\"Evaluate forecaster using timeseries cross-validation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : sktime.forecaster\n",
    "        Any forecaster\n",
    "    cv : Temporal cross-validation splitter\n",
    "        Splitter of how to split the data into test data and train data\n",
    "    y : pd.Series\n",
    "        Target time series to which to fit the forecaster.\n",
    "    X : pd.DataFrame, default=None\n",
    "        Exogenous variables\n",
    "    strategy : {\"refit\", \"update\"}\n",
    "        Must be \"refit\" or \"update\". The strategy defines whether the `forecaster` is\n",
    "        only fitted on the first train window data and then updated, or always refitted.\n",
    "    scoring : subclass of sktime.performance_metrics.BaseMetric, default=None.\n",
    "        Used to get a score function that takes y_pred and y_test arguments\n",
    "        and accept y_train as keyword argument.\n",
    "        If None, then uses scoring = MeanAbsolutePercentageError(symmetric=True).\n",
    "    fit_params : dict, default=None\n",
    "        Parameters passed to the `fit` call of the forecaster.\n",
    "    return_data : bool, default=False\n",
    "        Returns three additional columns in the DataFrame, by default False.\n",
    "        The cells of the columns contain each a pd.Series for y_train,\n",
    "        y_pred, y_test.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame that contains several columns with information regarding each\n",
    "        refit/update and prediction of the forecaster.\n",
    "    \"\"\"\n",
    "    _check_strategy(strategy)\n",
    "    cv = check_cv(cv, enforce_start_with_window=True)\n",
    "    scoring = check_scoring(scoring)\n",
    "    y = check_series(\n",
    "        y,\n",
    "        enforce_univariate=forecaster.get_tag(\"scitype:y\") == \"univariate\",\n",
    "        enforce_multivariate=forecaster.get_tag(\"scitype:y\") == \"multivariate\",\n",
    "    )\n",
    "    X = check_X(X)\n",
    "    fit_params = {} if fit_params is None else fit_params\n",
    "\n",
    "    # Define score name.\n",
    "    score_name = \"test_\" + scoring.name\n",
    "\n",
    "    # Initialize dataframe.\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    # Run temporal cross-validation.\n",
    "    for i, (train, test) in enumerate(cv.split(y)):\n",
    "        # split data\n",
    "        y_train, y_test, X_train, X_test = _split(y, X, train, test, cv.fh)\n",
    "\n",
    "        # create forecasting horizon\n",
    "        fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "\n",
    "        # fit/update\n",
    "        start_fit = time.perf_counter()\n",
    "        if i == 0 or strategy == \"refit\":\n",
    "            forecaster = clone(forecaster)\n",
    "            forecaster.fit(y_train, X_train, fh=fh, **fit_params)\n",
    "\n",
    "        else:  # if strategy == \"update\":\n",
    "            forecaster.update(y_train, X_train)\n",
    "        fit_time = time.perf_counter() - start_fit\n",
    "\n",
    "        # predict\n",
    "        start_pred = time.perf_counter()\n",
    "        if scoring.get_tag(\"scitype:y_pred\") == \"pred_quantiles\":\n",
    "            y_pred = forecaster.predict_quantiles(fh, X=X_test, **fit_params)\n",
    "        else:\n",
    "            y_pred = forecaster.predict(fh, X=X_test)\n",
    "\n",
    "        pred_time = time.perf_counter() - start_pred\n",
    "\n",
    "        # score\n",
    "        score = scoring(y_test, y_pred, y_train=y_train)\n",
    "\n",
    "        # save results\n",
    "        results = results.append(\n",
    "            {\n",
    "                score_name: score,\n",
    "                \"fit_time\": fit_time,\n",
    "                \"pred_time\": pred_time,\n",
    "                \"len_train_window\": len(y_train),\n",
    "                \"cutoff\": forecaster.cutoff,\n",
    "                \"y_train\": y_train if return_data else np.nan,\n",
    "                \"y_test\": y_test if return_data else np.nan,\n",
    "                \"y_pred\": y_pred if return_data else np.nan,\n",
    "            },\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "    # post-processing of results\n",
    "    if not return_data:\n",
    "        results = results.drop(columns=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "    results[\"len_train_window\"] = results[\"len_train_window\"].astype(int)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def _split(y, X, train, test, fh):\n",
    "    \"\"\"Split y and X for given train and test set indices.\"\"\"\n",
    "    y_train = y.iloc[train]\n",
    "    y_test = y.iloc[test]\n",
    "\n",
    "    cutoff = y_train.index[-1]\n",
    "    fh = check_fh(fh)\n",
    "    fh = fh.to_relative(cutoff)\n",
    "\n",
    "    if X is not None:\n",
    "        X_train = X.iloc[train, :]\n",
    "\n",
    "        # We need to expand test indices to a full range, since some forecasters\n",
    "        # require the full range of exogenous values.\n",
    "        test = np.arange(test[0] - fh.min(), test[-1]) + 1\n",
    "        X_test = X.iloc[test, :]\n",
    "    else:\n",
    "        X_train = None\n",
    "        X_test = None\n",
    "\n",
    "    return y_train, y_test, X_train, X_test\n",
    "\n",
    "\n",
    "def _check_strategy(strategy):\n",
    "    \"\"\"Assert strategy value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strategy : str\n",
    "        strategy of how to evaluate a forecaster\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If strategy value is not in expected values, raise error.\n",
    "    \"\"\"\n",
    "    valid_strategies = (\"refit\", \"update\")\n",
    "    if strategy not in valid_strategies:\n",
    "        raise ValueError(f\"`strategy` must be one of {valid_strategies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.05      0.95\n",
      "0  0.008705  0.007918\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_PinballLoss</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time</th>\n",
       "      <th>len_train_window</th>\n",
       "      <th>cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05      0.95\n",
       "0  0.008705  0.007918</td>\n",
       "      <td>0.00721</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>24</td>\n",
       "      <td>1959-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              test_PinballLoss  fit_time  pred_time  \\\n",
       "0         0.05      0.95\n",
       "0  0.008705  0.007918   0.00721   0.008943   \n",
       "\n",
       "   len_train_window   cutoff  \n",
       "0                24  1959-12  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(f, cv, y_test, scoring=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other solution\n",
    "A different option would be to change forecasters so that they included a default implementation for predict. \n",
    "\n",
    "```{python}\n",
    "forecaster():\n",
    "    def __init__(self):\n",
    "        self.pred_default = \"point\"\n",
    "        pred_types = {\n",
    "            \"point\":self._predict, \n",
    "            \"quantile\":self._predict_quantile,\n",
    "            \"interval\":self._predict_interval}\n",
    "\n",
    "    def _predict(self, X, fh):\n",
    "        notimplementederror()\n",
    "\n",
    "    def _predict_quantile(self, X, fh):\n",
    "        notimplementederror()\n",
    "\n",
    "    def _predict_interval(self, X, fh):\n",
    "        notimplementederror()\n",
    "\n",
    "    def predict(self, X, fh, type = None):\n",
    "        if type = None:\n",
    "            type = self.pred_default\n",
    "\n",
    "    return pred_types[type](X, fh)\n",
    "        \n",
    "```\n",
    "\n",
    "This would require changing the base class of forecasters and also still wouldn't solve the issue of how we pass what quantiles we need to the predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a4c1bd0c18409b39182e485d44e43f5e8ac7e8a10c8ff2f588fba96b8a44a80"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('sktime')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
